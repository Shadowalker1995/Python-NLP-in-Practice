# 2. Pytorch的初步应用

[toc]

## 2.1 使用Pytorch构建一个神经网络

- 关于`torch.nn`:
    - 使用 Pytorch 来构建神经网络, 主要的工具都在`torch.nn`包中
    - `nn`依赖于`autograd`来定义模型, 并对其自动求导

- 构建神经网络的典型流程：
    - 定义一个拥有可学习参数的神经网络
    - 遍历训练数据集
    - 处理输入数据使其流经神经网络
    - 计算损失值
    - 将网络参数的梯度进行反向传播
    - 以一定的规则更新网络的权重

- 我们首先定义一个Pytorch实现的神经网络

```python
# 导入若干工具包
import torch
import torch.nn as nn
import torch.nn.functional as F

# 定义一个简单的网络类
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        # 定义第一层卷积神经网络, 输入通道维度=1, 输出通道维度=6, 卷积核大小3*3
        self.conv1 = nn.Conv2d(1, 6, 3)
        # 定义第二层卷积神经网络, 输入通道维度=6, 输出通道维度=16, 卷积核大小3*3
        self.conv2 = nn.Conv2d(6, 16, 3)
        # 定义第三层全连接网络
        self.fc1 = nn.Linear(16 * 6 * 6, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        # 在(2, 2)的池化窗口下执行最大化池化操作
        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        # 经过卷积层的处理后, 张量要进入全连接层, 进入前需要调整张量的形状
        x = x.view(-1, self.num_flat_features(x))
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
    
    def num_flat_features(self, x):
        # 计算size, 除了第0个维度上的batch_size
        size = x.size()[1:]
        num_features = 1
        for s in size:
            num_features *= s
        return num_features

net = Net()
print(net)
```

```python
Net(
  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))
  (fc1): Linear(in_features=576, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)

```

- 模型中所有可训练参数, 可以通过`net.parameters()`来获得

```python
params = list(net.parameters())
print(len(params))
print(params[0].size())
```

```python
10
torch.Size([6, 1, 3, 3])
```

- 假设图像的输入尺寸为 32*32

```python
input = torch.randn(1, 1, 32, 32)
out = net(input)
print(out)
print(out.size())
```

```python
tensor([[ 0.1548, -0.0348, -0.0025,  0.0806, -0.1760,  0.1829,  0.0336, -0.0249,
         -0.0639, -0.1177]], grad_fn=<AddmmBackward>)
torch.Size([1, 10])
```

- 有了输出张量后, 就可以执行梯度归零和反向传播的操作了

```python
net.zero_grad()
out.backward(torch.randn(1, 10))
```

- **注意**：
    - `torch.nn`构建的神经网络只支持 mini-batch 的输入, 不支持单一样本的输入
    - 比如: `nn.Conv2d`需要一个 4D Tensor, 形状为`(nSamples, nChannels, Height, Width)`, 如果你的输入只有单一样本的形式, 则需要执行`input.unsqueeze(0)`主动将 3D Tensor 扩充为 4D Tensor

### 损失函数

- 损失函数的输入是一个输入 pair: `(output, target)`, 然后计算出一个数值来评估`output`和`target`之间的差距大小
- 在`torch.nn`中有若干不同的损失函数可供使用, 比如`nn.MSELoss`就是通过计算均方差损失来评估输入和目标之间的差距

- 应用`nn.MSELoss`计算损失的一个例子：

```python
output = net(input)
target = torch.randn(10)

# 改变target的形状为二维张量, 为了和output匹配
target = target.view(1, -1)
criterion = nn.MSELoss()

loss = criterion(output, target)
print(loss)
```

```python
tensor(0.8006, grad_fn=<MseLossBackward>)
```

- 当调用`loss.backward()`时, 整张计算图将对 loss 进行自动求导, 所有属性`requires_grad=True`的 Tensors 都将参与梯度求导的运算, 并将梯度累加到 Tensors 中的`.grad`属性中

```python
print(loss.grad_fn)		# MSELoss
print(loss.grad_fn.next_functions[0][0])	#Linear
print(loss.grad_fn.next_functions[0][0].next_functions[0][0])	# ReLU
```

```python
<MseLossBackward object at 0x7fe889e56710>
<AddmmBackward object at 0x7fe99b022f50>
<AccumulateGrad object at 0x7fe889e56710>
```

### 反向传播 (backpropagation)

- 在 Pytorch 中执行反向传播非常简便, 全部的操作就是`loss.backward()`
- 在执行反向传播之前, 要先将梯度清零, 否则梯度会在不同的批次数据之间被累加

- 执行一个反向传播的小例子

```python
# Pytorch中执行梯度清零的代码
net.zero_grad()

print('conv1.bias.grad before backward')
print(net.conv1.bias.grad)

# Pytorch中执行反向传播的代码
loss.backward()

print('conv1.bias.grad after backward')
print(net.conv1.bias.grad)
```

```python
conv1.bias.grad before backward
tensor([0., 0., 0., 0., 0., 0.])
conv1.bias.grad after backward
tensor([ 0.0017,  0.0107,  0.0002, -0.0154,  0.0092, -0.0112])
```

### 更新网络参数

- 更细参数最简单的算法就是 SGD (随机梯度下降)
- 具体的算法公式表达为: `weight = weight - learning_rate * gradient`

- 首先用传统的 Python 代码来实现 SGD 如下

```python
learning_rate = 0.01
for f in net.parameters():
    f.data.sub_(f.grad.data * learning_rate)
```

- 然后使用 Pytorch 官方推荐的标准代码如下

```python
# 首先导入优化器的包, optim中包含若干常用的优化算法, 比如SGD, Adam等
import torch.optim as optim

# 通过optim创建优化器对象
optimizer = optim.SGD(net.parameters(), lr=0.01)

# 将优化器执行梯度清零的操作
optimizer.zero_grad()

output = net(input)
loss = criterion(output, target)

# 对损失值执行反向传播的操作
optimizer.step()
```

## 2.2 使用Pytorch构建一个分类器

### 分类器任务和数据介绍

- 构建一个将不同图像进行分类的神经网络分类器, 对输入图片进行判别并完成分类
- 本案例采用 CIFAR10 数据集作为原始图片数据

> CIFAR10 数据集介绍：数据集中每张图片的尺寸是 3 * 32 * 32, 代表彩色 3 通道
>
> CIFAR10 数据集总共有 10 种不同的分类, 分别是 "airplane", "automobile", "bird", "cat", "deer", "dog", "frog", "horse", "ship", "truck".

- CIFAR10 数据集的样例图如下图所示

<img src="2.Pytorch%E7%9A%84%E5%88%9D%E6%AD%A5%E5%BA%94%E7%94%A8.assets/4fdf2b82-2bc3-4f97-ba51-400322b228b1.png" alt="img" style="zoom:50%;" />

### 训练分类器的步骤

1. 使用`torchvision`下载 CIFAR10 数据集
2. 定义卷积神经网络
3. 定义损失函数
4. 在训练集上训练模型
5. 在测试集上测试模型

1. **使用`torchvision`下载 CIFAR10 数据集**

- 导入`torchvision`包来辅助下载数据集

```python
import torch
import torchvision
import torchvision.transforms as transforms
```

- 下载数据集并对图片进行调整, 因为`torchvision`数据集的输出是 PILImage 格式, 数据域在$[0,1]$. 将其转换为标准数据域$[-1,1]$的张量格式

```python
transform = transforms.Compose(
	[transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                       download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,
                                         shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                       download=False, transform=transform)
testloader = torch.utils.data.DataLoader(trainset, batch_size=4,
                                         shuffle=False, num_workers=2)

classes = ('airplane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
```

```python
Using downloaded and verified file: ./data/cifar-10-python.tar.gz
Extracting ./data/cifar-10-python.tar.gz to ./data
```

- 展示若干训练图片

```python
import matplotlib.pyplot as plt
import numpy as np

# 构建展示图片的函数
def imshow(img):
    img = img / 2 + 0.5
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()   

# 从数据迭代器中读取一张图片
dataiter = iter(trainloader)
images, labels = dataiter.next()

# 展示图片
imshow(torchvision.utils.make_grid(images))
# 打印标签label
print(' '.join('%5s' % classes[labels[j]]))
```

<img src="2.Pytorch%E7%9A%84%E5%88%9D%E6%AD%A5%E5%BA%94%E7%94%A8.assets/image-20221014010110448.png" alt="image-20221014010110448" style="zoom:50%;" />

```python
horse   cat airplane truck
```

2. **定义卷积神经网络**

- 仿照2.1节中的类来构造此处的类, 唯一的区别是此处采用 3 通道 3-channel

```python
import torch.nn as nn
import torch.nn.functional as F


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5* 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

net = Net()
```

3. **定义损失函数**

- 采用交叉熵损失函数和随机梯度下降优化器

```python
import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
```

4. **在训练集上训练模型**

- 采用给予梯度下降的优化算法, 都需要很多个轮次的迭代训练

```python
for epoch in range(2):	# loop over the dataset multiple times
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # data中包含输入图像张量inputs, 标签张量labels
        inputs, labels = data
        
        # 首先将优化器梯度归零
        optimizer.zero_grad()
        
        # 输入图像张量进网络, 得到输出张量outputs
        outputs = net(inputs)
        
        # 利用网络的输出outputs和标签labels计算损失值
        loss = criterion(outputs, labels)
        
        # 反向传播+参数更新, 是标准代码的标准流程
        loss.backward()
        optimizer.step()
        
        # 打印轮次和损失值
        running_loss += loss.item()
        if (i +1) % 2000 == 0:
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0

print('Finished Training')
```

```python
[1,  2000] loss: 2.221
[1,  4000] loss: 1.897
[1,  6000] loss: 1.694
[1,  8000] loss: 1.582
[1, 10000] loss: 1.505
[1, 12000] loss: 1.457
[2,  2000] loss: 1.413
[2,  4000] loss: 1.386
[2,  6000] loss: 1.354
[2,  8000] loss: 1.363
[2, 10000] loss: 1.319
[2, 12000] loss: 1.295
Finished Training
```

- 保存模型

```python
# 首先设定模型的保存路径
PATH = './models/cifar_net.pth'
# 保存模型的状态字典
torch.save(net.state_dict(), PATH)
```

5. **在测试集上测试模型**

- 第一步, 展示测试集中的若干照片

```python
dataiter = iter(testloader)
images, labels = dataiter.next()

# 打印原始图片
imshow(torchvision.utils.make_grid(images))
# 打印真实的标签
print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))
```

- 输出图片结果

<img src="2.Pytorch%E7%9A%84%E5%88%9D%E6%AD%A5%E5%BA%94%E7%94%A8.assets/image-20221014012328484.png" alt="image-20221014012328484" style="zoom:50%;" />

- 输出标签结果

```python
GroundTruth:   frog truck truck  deer
```

- 第二步, 加载模型并对测试图片进行预测

```python
# 首先实例化模型的类对象
net = Net()
# 加载训练阶段保存好的模型的状态字典
net.load_state_dict(torch.load(PATH))

# 利用模型对图片进行预测
outputs = net(images)

# 共有10个类别, 采用模型计算出概率最大的最为预测的类别
_, predicted = torch.max(outputs, 1)

# 打印预测标签的结果
print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))
```

```python
Predicted:   deer truck truck  deer
```

- 接下来看一下在全部测试集上的表现

```python
correct = 0
total = 0
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the 10000 test images: %d %%' % (
    100 * correct / total))
```

```python
Accuracy of the network on the 10000 test images: 54 %
```

> 分析结果: 对于拥有 10 个类别的数据集, 随机猜测的准确率是 10%, 模型达到了 53%, 说明模型学到了真实的东西

- 为了更加细致的看一下模型在哪些类别上表现更好, 在哪些类别上表现更差, 我们分类别的进行准确率计算

```python
class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        c = (predicted == labels).squeeze()
        for i in range(4):
            label = labels[i]
            class_correct[label] += c[i].item()
            class_total[label] += 1

for i in range(10):
    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))
```

```python
Accuracy of airplane : 66 %
Accuracy of   car : 65 %
Accuracy of  bird : 42 %
Accuracy of   cat : 49 %
Accuracy of  deer : 59 %
Accuracy of   dog : 31 %
Accuracy of  frog : 58 %
Accuracy of horse : 56 %
Accuracy of  ship : 66 %
Accuracy of truck : 44 %
```

### 在GPU上训练模型

- 为了真正利用 Pytorch 中 Tensor 的优秀属性, 加速模型的训练, 我们可以将训练过程转移到 GPU 上进行

- 首先要定义设备, 如果 CUDA 是可用的则被定义成 GPU, 否则被定义成 CPU

```python
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(device)
```

```python
cuda:0
```

- 当训练模型的时候, 只需要将模型转移到 GPU 上, 同时将输入的图片和标签也转移到 GPU上 即可

```python
# 将模型转移到GPU上
net.to(device)

# 将输入的图片张量和标签张量转移到GPU上
inputs, labels = data[0].to(device), data[1].to(device)
```
